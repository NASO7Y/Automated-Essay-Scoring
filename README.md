# ğŸ“ Automated Essay Scoring 

This project presents a **Machine Learning and NLP-based solution for Automated Essay Scoring (AES)**. It simulates the grading of essays written in natural language, using a range of linguistic and statistical features to predict scores â€” closely mimicking human evaluation.

ğŸ”— [View the Notebook](https://github.com/NASO7Y/Automated-Essay-Scoring/blob/main/Automated-Essay-Scoring-NLP-ML.ipynb)

---

## ğŸ“Œ Project Overview

Automated Essay Scoring (AES) refers to the use of machine learning and NLP techniques to automatically grade essays. In this project, we create a **synthetic dataset** that mimics real student essays, complete with scores, grammar mistakes, and varying writing styles.

The notebook:
- Generates a dataset of artificial essays.
- Extracts linguistic, statistical, and readability features.
- Trains machine learning models to predict scores.
- Evaluates the models using standard metrics.

---

## ğŸš€ Technologies Used

- **Python 3.9**
- **Pandas, NumPy** â€“ data handling
- **NLTK, TextStat** â€“ NLP and readability analysis
- **Scikit-learn** â€“ model training and evaluation
- **Matplotlib, Seaborn** â€“ visualizations

---

## ğŸ“‚ Dataset

Unlike traditional AES projects that rely on external datasets (like those from Kaggle), this project **generates a synthetic dataset** of essays directly within the code. Each generated essay includes:

- Essay text  
- A synthetic score (based on quality metrics)  
- Artificial errors (spelling, grammar, etc.)

This allows flexibility and full control over feature distribution and label generation for experimentation.

---

## ğŸ” Key Features Extracted

- **Grammatical Features**: Parts-of-speech tagging, grammar errors  
- **Lexical Richness**: Word diversity, sentence structure  
- **Readability Scores**: Flesch Reading Ease, Gunning Fog Index  
- **Spelling Errors**: Introduced intentionally for training  
- **Essay Length & Structure**: Number of sentences, words, characters

---

## ğŸ¤– Models Used

- **Linear Regression**
- **Random Forest Regressor**
- **Gradient Boosting Regressor**
- **Support Vector Regressor (SVR)**

### Evaluation Metrics:
- **Mean Squared Error (MSE)**
- **RÂ² Score**

---

## ğŸ§ª How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/NASO7Y/Automated-Essay-Scoring.git
   cd Automated-Essay-Scoring
   ```

2. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

3. Launch the notebook:
   ```bash
   jupyter notebook Automated-Essay-Scoring-NLP-ML.ipynb
   ```

### âš ï¸ Notes:
- Make sure to download required **NLTK resources** before running:
  ```python
  import nltk
  nltk.download('punkt')
  nltk.download('averaged_perceptron_tagger')
  nltk.download('stopwords')
  ```

- Download **spaCy English model** if not already installed:
  ```bash
  python -m spacy download en_core_web_sm
  ```

  
---

## ğŸ“¬ Contact

ğŸ“§ [LinkedIn](linkedin.com/in/nos7y/)  
ğŸ”— [GitHub](https://github.com/NASO7Y)
